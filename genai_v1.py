# -*- coding: utf-8 -*-
"""GenAI_V1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xaoD81_QRUlR3XobD2G8UNFPsbwkjWvY

# EDA
"""
import streamlit as st
import pandas as pd
from langchain.chat_models import ChatOpenAI

# Page title
st.set_page_config(page_title='ðŸ¦œðŸ”— Elite Finance')
st.title('ðŸ¦œðŸ”—Elite Finance')

"""# Gen AI : Elite Finance"""



from langchain_experimental.agents import create_csv_agent
from langchain.llms import Cohere


agent = create_csv_agent(Cohere(temperature=0, cohere_api_key="sMtMgxOL4fxZtpW0OOFtLFraoAXCsq0FXYwoV0Xi", model = 'command-nightly'),
                         'ECI_Product_Dataset.csv',
                         verbose=True)


#agent.cohere.llm_chain.prompt.template

# initialize the callback handler with a container to write to

import functools

# Define a cache for the expensive computations
@functools.lru_cache(maxsize=None)
def cache_agent_response(prompt, response):
    # Cache the response based on the prompt
    return response
    
if prompt := st.chat_input("Enter your question"):
    st.chat_message("user").write(prompt)
    with st.chat_message("assistant"):
        # Check if the result is already cached
        cached_response = cache_agent_response(prompt, None)
        if cached_response is not None:
            response = cached_response
        else:
            # Perform the expensive computation and cache the result
            response = agent.run(prompt)
            cache_agent_response(prompt, response)

        st.write(response)

